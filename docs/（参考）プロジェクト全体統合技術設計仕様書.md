## ペアトレードAIシステム 技術設計仕様書（基礎構成）

### ✅ 基本方針

安定性・再現性・拡張性を重視し、**シングルスレッド × マルチプロセス構成**で運用する。
各プロセスが独立してペア群を担当し、OSレベルで並列動作することで高い信頼性を確保する。

---

### 🧩 開発環境

| 項目      | 内容                                                                                  |
| ------- | ----------------------------------------------------------------------------------- |
| 言語      | Python 3.11（安定版、主要MLライブラリ完全対応）                                                      |
| 主要ライブラリ | pandas, numpy, scikit-learn, xgboost/lightgbm, SQLAlchemy, redis, psycopg2, sqlite3 |
| OS構成    | Linux（学習・再学習）＋ Windows VPS（MT5運用）                                                   |
| 並列設計    | シングルスレッド × マルチプロセス（5〜10ペア／プロセス）                                                     |
| 開発補助    | Cursor Ultra（コード自動生成・統合）                                                            |

---

### 🧠 システム構成概要

```
┌────────────────────────────┐
│ 学習・分析層（PostgreSQL）                              │
│  - 過去データ・特徴量・zスコア・学習結果を永続保存     │
│  - ラベリング・再学習・評価用データベース               │
└────────────────────────────┘
               ▲
               │ 月次更新
               ▼
┌────────────────────────────┐
│ 運用層（SQLite：各プロセス内ローカルDB）               │
│  - 直近の価格・スプレッドキャッシュ                    │
│  - JSON/CSVより高速・安全に保持                        │
└────────────────────────────┘
               ▲
               │ リアルタイム共有
               ▼
┌────────────────────────────┐
│ 即時通信層（Redis）                                    │
│  - signal/zスコア/状態共有                            │
│  - Pub/SubまたはHashによる即時伝達                    │
└────────────────────────────┘
```

---

### 💾 データ保存方式と用途

| 層   | ストレージ      | 用途              | 更新頻度  | 備考               |
| --- | ---------- | --------------- | ----- | ---------------- |
| 学習層 | PostgreSQL | 長期データ・学習履歴・特徴量  | 日次〜月次 | ACID保証、集計・分析用    |
| 運用層 | SQLite     | 各プロセスのローカルキャッシュ | 秒〜分   | JSONより高速、ロック競合なし |
| 通信層 | Redis      | signal共有・状態同期   | ミリ秒単位 | Pub/Sub、Lock不要   |

---

### ⚙️ 並列処理モデル

* 各プロセスは完全独立（1プロセス＝1戦略群＝5〜10ペア）
* OSスケジューラによるCPUコア分配で真の並列化（GIL回避）
* プロセス間通信はRedis経由で非同期に共有
* 障害時はsystemd/supervisorで個別再起動

---

### 🧩 データフロー概要

1. **TwelveData API（Pro $99/月）** から過去＋リアルタイムデータ取得
2. PostgreSQLに履歴保存 → ラベリング・学習
3. 学習モデル（pkl）を各プロセスへ配布
4. 各プロセスがSQLiteに直近データキャッシュ
5. 推論結果（signal）をRedisで共有・監視
6. MT5 EAがsignal.jsonを監視 → 自動発注
7. 月次で再学習・モデル更新 → 自動反映

---

### 🤖 機械学習要件（詳細）— ラベリング仕様 v1

- 共通前提
  - 時間足: デフォルト 1h。設定で 15m/1h/4h 切替可。学習データは対象足で最低 24 ヶ月相当のバー数、推論は対象足の確定バー基準。
  - β 推定: ローリング OLS 窓 180 バー。残差の MAD 比 > 2.0 でロバスト回帰（Huber）に自動切替。更新は各バー。係数は EMA（半減期 72 バー）で平滑化。
  - z 標準化: ローリング窓 180 バーの μ/σ。±5σ でクリップ、z は EMA 平滑（半減期 12 バー）。再計算は各バー。

- 時間足設定ポリシー
  - 設定キー（例）: `timeframe_default: 1h`, `timeframe_allowed: [15m, 1h, 4h]`
  - 窓・期間は「バー数」で定義（例: β 窓=180バー）。時間足変更時も同じバー数を適用し、一貫した統計特性を維持。
  - 学習データ最小量は「バー数」基準（例: ≥ 24 ヶ月相当のバー）。15m/4h など切替時は必要バー数を自動換算。
  - リサンプリング: ネイティブ足を優先。やむを得ずリサンプルする場合は UTC 揃えで OHLC 集計し、終値ベースの特徴量はクローズ値を使用。
  - 一貫性: 学習・バックテスト・推論は同一時間足で実行（MTF 特徴量は次フェーズ）。
  - 検証: 将来 15m/1h/4h で KPI 比較（勝率/年率/最大DD/取引数/レイテンシ耐性）を行い、運用足を再評価。

- AI1（回帰確率）ラベル定義
  - イベント起点: |z_t| ≥ z_entry。推奨初期値 z_entry = 2.0。
  - 成功判定: 起点から M バー以内（M = 48）に |z| ≤ z_exit（z_exit = 0.5）到達で 1、未到達は 0。
  - 方向: z > 0 → A 売 / B 買、z < 0 → A 買 / B 売。
  - 再エントリー抑制: 有効イベント窓中は同方向の新規イベントを抑止。逆方向クロス時は既存イベントをクローズし再ラベルを許可。
  - 重複防止: 起点から M 経過または Exit 成立まで、同一ペア・同方向のイベントは無効化。
  - 不利イベント除外: 直前 K=6 バーの平均 |Δz| > θ_speed（0.12/バー）時は起点候補から除外。

- AI2（リスク）ラベル定義
  - risk = 1 条件（いずれかを満たす）
    - 相関安定性低下: var(ρ_rolling, 窓 180) > θ_corr_var（0.025）
    - ボラ急騰: vol_ratio = ATR_now / ATR_median_180 > θ_vol（1.8）
    - 乖離速度過大: |Δz| の EMA（半減期 6）> θ_speed（0.12）
    - 直近 DD 拡大: dd_recent（60 営業日）> θ_dd（0.07）
  - risk = 0: 上記をすべて満たさない場合。
  - クラス不均衡: positive 比率に応じた class_weight（inverse frequency）。重み比は最大 1:5 にクリップ。

- データ品質（学習前処理）
  - 欠損: 連続欠損 ≤ 2 本は前方埋め + 線形補間、> 2 本は区間除外。
  - 外れ値: 価格変化が ±8σ 超過のバーは除外。ゼロ/負値は除外。
  - 時間整合: UTC 固定。バー確定時刻で A/B を同期し、足並び不一致バーは除外。

- 推奨初期パラメータまとめ
  - z_entry = 2.0、z_exit = 0.5、M = 48
  - β 窓 = 180、z 窓 = 180、EMA 半減期（z）= 12、EMA 半減期（β）= 72
  - θ_corr_var = 0.025、θ_vol = 1.8、θ_speed = 0.12、θ_dd = 0.07
  - 足 = 1h、学習期間 ≥ 24 ヶ月

---

### 🧮 特徴量仕様 v1（式・窓長・正規化）

- 基本定義
  - 価格系列: 終値（必要に応じて `p_t = ln(P_t)` を利用）
  - リターン: `r_t = ln(P_t / P_{t-1})`
  - スプレッド: `S_t = P_A(t) - β_t · P_B(t)`（βはローリング OLS 180 バー、EMA 平滑 半減期 72）
  - zスコア: `z_t = (S_t - μ_t) / σ_t`（μ,σ は 180 バー、±5σ でクリップ、EMA 半減期 12 で平滑）

- スプレッド系特徴量
  - `delta_z`: `Δz_t = z_t - z_{t-1}`
  - `z_ema`: z の EMA（半減期 12）
  - `atr_spread`: スプレッド `S_t` に対する Wilder ATR（期間 14）
  - `vol_ratio_spread`: `atr_spread_now / median(atr_spread, 180)`
  - `half_life`: 回帰半減期。`ΔS_t = κ (μ - S_{t-1}) + ε_t` を OLS 推定し `half_life = ln(2) / |κ|`（範囲クリップ `[1, 240]`）

- 相関・β系特徴量
  - `rho_rolling`: `corr(r_A, r_B)` のローリング相関（180 バー）
  - `corr_stability`: `var(rho_rolling, 180)`
  - `beta_stability`: `std(β, 180) / (|mean(β, 180)| + 1e-6)`

- ボラ・トレンド系特徴量
  - `atr_A`, `atr_B`: 各レッグの Wilder ATR（期間 14）
  - `atr_ratio_A`, `atr_ratio_B`: `atr_now / median(atr, 180)`
  - `ema_gap_spread`: `EMA_fast(S, 12) - EMA_slow(S, 26)`
  - `slope_spread`: 直近 20 バーの `S_t` に対するOLS傾き（`σ_S` でスケール）
  - `rsi_spread`: `S_t` の RSI（期間 14）

- イベント速度系
  - `abs_delta_S`: `|S_t - S_{t-1}|`
  - `abs_delta_z`: `|Δz_t|`
  - `slope_z`: 直近 20 バーの z に対する OLS 傾き

- 正規化・クリッピング方針
  - 連続値特徴量は学習期間内でロバスト標準化（中央値・MAD）を優先。外れ値は上下 1% タイルでウィンズor化。
  - モデル入力前に主要特徴量（z, Δz, slope 等）は `[-5, 5]` にクリップ。
  - 学習・推論間のスケール一貫性を保つため、正規化パラメータはメタ情報として保存。

- 計算・更新ポリシー
  - 窓・期間は「バー数」基準（時間足変更時も同一バー数を適用）。
  - すべてのローリング統計はインクリメンタル更新（累積和/二乗和/EMA）で計算。
  - 中間統計（μ, σ, β, atr, 相関行列）はキャッシュし、バー確定時に1回更新。

- 推奨窓長（初期値）
  - `β`: 180 / `β_ema_half_life`: 72
  - `z`: 180 / `z_ema_half_life`: 12
  - `atr(legs/spread)`: 14 / `atr_baseline_median`: 180
  - `rho_rolling`: 180 / `slope_window`: 20

---

### 🧪 時系列CV・評価KPI 仕様 v1

- CV設計（リーク防止）
  - 方式: Purged Grouped TimeSeries K-Fold（K=5）
  - グルーピング: 時系列ブロック（時間順）。同一ペアの連続性を保持し分割
  - パラメータ: `purge_bars = 24`, `embargo_bars = 24`, `min_block_len_bars = 240`
  - 目的: 先読み・重複イベントのリーク抑制（`z_window`/`beta_window`/`M` を考慮した最小ブロック長）

- ウォークフォワード（OOS）
  - 方式: Expanding Window Walk-Forward
  - ステップ: `wf_step_days = 30` 相当のバー数（時間足に応じ換算）
  - 最小学習範囲: `wf_min_train_days = 360` 相当のバー数
  - 手順: 学習→OOS評価→次ステップへ拡張。全ステップを集約してKPI算出

- 学習時の評価指標（分類確率）
  - AI1: `AUC`, `Brier`, `PR-AUC`, `Calibration-ECE`
  - AI2: `F1@risk=1`（加重）, `PR-AUC`, `Recall@低リスク帯`
  - 確率キャリブレーション: Isotonic（検証Foldで学習）を推奨

- 統合戦略のKPI（バックテスト/OOS）
  - 収益: 年率（単純/複利近似）, `E/trade`, `trades/yr`, 月次勝率
  - リスク: `MaxDD`, `Sharpe`（日次換算）, `Calmar/MAR`, `PnLσ`
  - 品質: `やらない勇気発動率(10–40%)`, `risk_flag precision/recall`, `θ1/θ2通過率`
  - 運用: 連敗数分布, レイテンシ影響（任意）

- 採用判定（旧モデル比較, 多目的）
  - 基準: `Sharpe_new ≥ 0.95 × Sharpe_old`, `MaxDD_new ≤ MaxDD_old + 0.03`
  - 追加: `Stop誤検出率(AI2) < 10%`, `E/trade_new ≥ 0`
  - 信頼区間: ブロックブートストラップ（`block_size_bars = 20`）で 95% CI。改善の下限が非負であれば合格
  - 統計検定: Diebold–Mariano（週次集計リターン）で優位性 p < 0.10 参考

- 過学習抑制
  - 早期停止: LightGBM/XGBoost `early_stopping_rounds = 50`
  - 検証分割: 各Fold内で train/valid（時系列順）をさらに分け、指標は上記
  - 乱数: `seed` 固定、Fold差の分散をKPIに併記

- 設計ポリシー
  - すべての長さは「バー数」で定義（時間足切替に対して不変）
  - KPIは OOS と CV の両方を提示し、OOS を優先
  - エクイティカーブは対象足で作成し日次に再集計して Sharpe/MaxDD を算出

- 推奨初期値（設定キー例）
  - `k_folds: 5`, `purge_bars: 24`, `embargo_bars: 24`, `min_block_len_bars: 240`
  - `wf_step_days: 30`, `wf_min_train_days: 360`, `block_bootstrap_size_bars: 20`

---

### 🎯 閾値最適化（θ1/θ2）仕様 v1

- 目的関数（多目的のスカラー化）
  - 目的: 年率期待リターンを最大化しつつ、最大DD・取引数・誤停止率を制御
  - スコア例（OOS集計に対して）:
    - `Score = AnnualizedReturn − λ_dd · max(0, MaxDD − dd_target) − λ_trades · max(0, trades_min − trades_per_year) − λ_stop · FP_rate_AI2`
  - 推奨初期値: `dd_target = 0.12`, `trades_min = 150/年`, `λ_dd = 2.0`, `λ_trades = 0.05`, `λ_stop = 0.10`

- 制約（ハード制約）
  - `MaxDD ≤ 0.12` を満たさない解は不採用
  - `trades_per_year ≥ 150` 未満の解は不採用（データ効率・実務性）
  - `AI2 false_positive_rate ≤ 10%` 未満を推奨（過剰停止の抑制）

- 探索空間・アルゴリズム
  - 探索範囲（既定）: `θ1 ∈ [0.60, 0.85]`, `θ2 ∈ [0.20, 0.45]`（`core_policy.yaml` と整合）
  - 段階的探索: 粗グリッド（刻み 0.02）→ ベイズ最適化（Optuna TPE, 50〜100 試行, early stop 15）
  - 評価データ: Purged K-Fold + Walk-Forward の OOS を加重集約（OOSを優先）
  - 出力: Top-1 と Pareto 上位（Sharpe 高, MaxDD 低）の候補集合

- 粒度と適用スコープ
  - 既定: クラスタ/戦略グループ単位で `θ1, θ2` を採用（グローバル基準）
  - 例外: ペア固有性が強い場合のみ `Δθ` を許容（`|Δθ| ≤ 0.05`）
  - ロールアウト: まず 20% のペアへ 2 週間カナリア適用 → KPI 良好で全体適用

- 安定化（ヒステリシス）
  - 変更幅制限: `|θ_new − θ_old| ≤ 0.03/回`
  - 平滑化: `θ_applied = 0.7 · θ_old + 0.3 · θ_new`（EWMA, 半減期 ≈ 3 ヶ月）
  - データ不足時の据え置き: OOS 取引数が `trades_min/2` 未満なら更新保留
  - 反証ガード: 改善が信頼区間下限で 0 を下回る場合は更新しない（95% CI, ブロックブートストラップ）

- デプロイ・ロールバック
  - 採用判定: 上記スコア・制約を満たし、旧モデル対比の非劣性を確認
  - 監査: `model_registry` と `audit.config_changes` に `θ1/θ2`, 指標, 期間, 追跡ID を保存
  - ロールバック: 重大悪化（Sharpe -20% or MaxDD +3% 超）で即時旧 `θ` に復帰

- スケジュール・運用
  - 頻度: 月次（`retrain_cron` と同調）
  - 手動上書き: UI→Git→PR→承認で `core_policy.yaml` を更新
  - 出力物: 採用 `θ1/θ2`, 候補リスト, KPI サマリ, 95% CI, 変更差分, コメント

- 実装指針
  - すべての窓長・閾値は「バー数」/スカラーで時間足非依存に設計
  - 再現性: `seed`, データハッシュ, コードハッシュをログ
  - ログ: 失敗試行含む全試行の `θ1/θ2` と KPI を保存（後分析・再現用）

---

### 📦 data-assets-pipeline 仕様 v1（ETL/DQ/スケジュール）

- 目的・範囲
  - TwelveData からの取得→整形→品質検査→スプレッド/β/z の基礎計算→学習/BT向けデータ出力までを担当
  - 出力は学習/BT/推論で共通利用できる「時間足別・銘柄別の正規化済みバー＋メタ」を提供（DB/Parquetは環境に応じ選択）

- 入力・出力（論理スキーマ）
  - 入力（REST）: symbol, timeframe, start/end, limit
  - 入力（WS）: symbols[], timeframe(or tick), heartbeat
  - 出力（バー）: `ts_utc, symbol, timeframe, open, high, low, close, volume, quality_flag`
  - 出力（派生）: `beta_t, spread_t, z_t, z_ema, atr_A, atr_B, atr_spread, rho_rolling`
  - 出力（メタ）: `last_refreshed_ts, source, window_params, dq_counters`
  - 注: 物理テーブル/コレクション名は未確定。ここでは列定義のみを固定（契約）

- ETL 手順（学習/日次）
  1. 取得: timeframe ごとに過去 24 ヶ月相当の履歴を分割取得（ウォーターマークで増分）
  2. 整形: UTC 揃え、シンボル正規化、重複/順不同の解消、OHLCV の型保証
  3. DQ 検査: 欠損・外れ値・スパイク・ギャップ検知（下記ルール）
  4. 基礎計算: β(180, EMA半減期72)、S_t、z(180, clip±5σ, EMA半減期12)、ATR(14)、相関(180)
  5. 保存: バー/派生/メタを同一パーティションへ保存（idempotent 上書き）
  6. レポート: DQ 要約（欠損率・outlier率・リトライ回数など）をメタへ集計

- ETL 手順（運用/分〜時間）
  - 差分取得: REST の latest バー or WS 集計で 1 本生成
  - 同期: 最新バーが確定した時点で基礎計算をインクリメンタル更新
  - フェイルセーフ: WS 断時は REST で再同期、遅延>しきい値で signal 抑制フラグを出力

- DQ（データ品質）ルール
  - 欠損: 連続欠損 ≤ 2 本は前方埋め+線形補間、>2 本は区間除外・quality_flag=missing
  - 外れ値: 終値リターンが ±8σ 超過で除外・quality_flag=outlier
  - 重複/逆順: timestamp 一意性担保。重複は最新受信で上書き
  - スパイク: `|Δclose| > k_spike · median(|Δclose|, 180)` でフラグ（k_spike=12）
  - β安定: `std(β,180)` が異常上昇で注意フラグ（後段AI2で利用）
  - 閾値: 欠損率>5% or outlier率>8% で学習出力を隔離（運用へ停止通知は別層が担当）

- スケジュール/取得制御
  - 学習/日次: 夜間一括（timeframe 別ジョブ）。過去差分+DQ+派生計算
  - 運用/常時: WS 優先、1m/5m 集計→対象時間足へローリング確定
  - レート制限: Pro 枠（REST 610, WS 500）を超えないようシンボルバッチ・バックオフ（指数関数: 1x,2x,4x,上限60s）
  - リトライ: HTTP 429/5xx は最大 5 回、idempotent 再実行

- ストレージ/パーティション（物理は環境依存、規約のみ記載）
  - パーティションキー: `timeframe / symbol / YYYY-MM`
  - ファイル命名例（Parquet）: `{timeframe}/{symbol}/{YYYY}/{YYYY-MM}/{symbol}_{YYYY-MM-DD}.parquet`
  - 列型: `ts_utc: timestamptz, price: numeric(必要精度), volume: numeric`
  - メタは同フォルダに `__meta.json`（last_refreshed_ts, counts, window_params）

- 設定鍵（例、名称は将来のconfigに委譲）
  - `timeframe_default`, `timeframe_allowed`, `universe_symbols`
  - `history_lookback_months`, `beta_window_bars`, `z_window_bars`, `atr_period`
  - `dq_spike_k`, `missing_fill_max_run`, `outlier_sigma`
  - `rest_rate_limit_budget`, `retry_max`, `retry_backoff_max_seconds`

- 運用考慮
  - ウォーターマーク: シンボル×足の `last_ts` を保持し差分取得（再実行安全）
  - 監査/可観測性: 取得成功率、遅延、欠損率、outlier率、再試行回数をログ・メトリクス化
  - シークレット: APIキーは環境変数/Secret 管理。露出禁止
  - タイムゾーン: すべて UTC。サマータイム影響を無視できるよう統一

---

### 🗄 データ保持ポリシー v1（設定 YAML 管理）

- 方針
  - すべての保存期間は設定 YAML（例: `config/data_retention.yaml`）で管理し、コードにハードコードしない。
  - 最低保持は学習・特徴量計算に必要な「バー数」分を下回らないようガード（例: `z_window=180` なら、その期間を十分にカバー）。
  - 物理削除は日次バッチで実行し、グレース期間（既定 3 日）を設ける。

- 設定例（data_retention.yaml）
```yaml
raw_days:
  value: 60
  label_ja: "raw保持日数"
  description: "ソース生データ（REST/取込直後）の保持期間（日）。"

ws_ticks_hours:
  value: 48
  label_ja: "WSティック保持時間"
  description: "WebSocketティックの短期保持（時間）。"

canonical_months:
  value: 36
  label_ja: "カノニカル保持月数"
  description: "UTC整形・重複除去済みOHLCV（唯一の真実）の保持期間（月）。"

features_cache_months:
  value: 12
  label_ja: "特徴量キャッシュ保持月数"
  description: "再生成可能な特徴量のキャッシュ保持（月）。"

features_snapshot_months:
  value: 24
  label_ja: "採用スナップショット保持月数"
  description: "採用時点の特徴量/ラベルスナップショット保持（月）。"

model_artifacts_months:
  value: 24
  label_ja: "モデル成果物保持月数"
  description: "model.pkl/feature_schema/params 等の保持（月）。"

signals_history_months:
  value: 12
  label_ja: "シグナル履歴保持月数"
  description: "`core.signals_history` の保持期間（月）。"

reports_months:
  value: 24
  label_ja: "レポート保持月数"
  description: "PDF/CSVなど成果レポートの保持（月）。"

logs_days:
  value: 90
  label_ja: "ログ保持日数"
  description: "実行ログの保持（日）。重大ログは別設定。"

audit_logs_years:
  value: 5
  label_ja: "監査ログ保持年数"
  description: "監査/変更履歴の長期保持（年）。WORMストレージ推奨。"
```

- 運用ルール
  - 削除は段階的（logical delete → 物理削除）を許可。重大・監査データは WORM を優先。
  - 変更は UI→Git→PR→承認→適用→監査テーブル更新のワークフローに従う。
  - 依存ガード: 設定変更時に学習窓/評価期間を下回る値は拒否（バリデータ）。

---

### 🛠 監視・運用 / エラー時の振る舞い（data pipeline）v1

- 可観測性（Metrics/Logs/Trace）
  - Metrics（例、Prometheus 名）
    - `data_ingest_success_rate`（取り込み成功率）
    - `data_api_latency_ms`（REST/WS レイテンシ、p50/p95）
    - `data_missing_rate` / `data_outlier_rate`（欠損率 / 外れ値率）
    - `data_ws_reconnects_total`（WS再接続回数/日）
    - `data_pipeline_lag_seconds`（canonical への反映遅延）
    - `data_retry_total` / `data_dedupe_drops_total`（再試行 / 重複破棄）
    - `data_watermark_lag_bars`（ウォーターマーク遅延バー数）
    - `beta_stability_std` / `dq_fail_total`（β安定度 / DQ失敗件数）
  - Logs（構造化）: `ts, level, source, timeframe, symbol, run_id, ingest_run_id, event, details{...}`
  - Trace: 取得→整形→DQ→保存をスパン分割。`ingest_run_id` を親IDに紐付け。

- エラー時の動作
  - 再試行: 指数バックオフ + ジッタ（1s,2s,4s,8s… 上限 60s）。最大 `retry_max`。idempotent のみ再実行。
  - サーキットブレーカ: ソース/タイムフレーム単位で Open→Half-Open→Close。Open 中は代替経路へ切替。
  - フェイルオーバ: WS→REST（latest 再同期）。複数ソース定義時は `priority` に従い切替。
  - デグレード: `data_pipeline_lag_seconds` が `freshness_budget_seconds` 超過でシグナル抑制フラグ（別層が参照）。

- 隔離（Quarantine）
  - 条件: `missing_rate > 5%` または `outlier_rate > 8%` または `beta_stability_std` 急上昇。
  - 影響範囲: timeframe×symbol×年月パーティションを隔離し、学習・BT出力から除外。`__quarantine.json` に理由・閾値・時間範囲を記録。
  - 復旧: 再取得/補完→DQ再評価→閾値クリアで自動解除。手動解除は UI→PR→承認。

- アラート & エスカレーション
  - 重大: API ダウン > 10 分、`freshness_budget` 超過連続 > 3 本、DQ失敗連続 > 5 → PagerDuty + Slack `#risk-alerts`
  - 警告: 欠損/外れ値 閾値接近、WS 再接続が時間当たり > X、レイテンシ p95 悪化 → Slack `#ml-ops`
  - 情報: 再同期完了、隔離解除、設定変更適用 → Slack `#config-changes`

- SLA / SLO（初期値）
  - Freshness（canonical 反映遅延の上限）
    - 15m: ≤ 60s、1h: ≤ 120s、4h: ≤ 180s（`freshness_budget_seconds` で上書き可）
  - 取得成功率（日次）: ≥ 99.0%
  - DQ 合格率（日次）: ≥ 95.0%

- ランブック（簡易）
  - WS 切断多発: サーキット Open → REST 同期 → WS 再試行。閾値超過で警告通知。
  - 欠損急増: 対象期間を隔離 → 再取得（小分割）→ 補完 → DQ 再評価。
  - レイテンシ悪化: バッチ間隔調整/シンボル分割/レート制限見直し。

- セーフティ/一貫性
  - Idempotency Key: `(source, symbol, timeframe, ts)` で一意化。重複は破棄カウントへ。
  - At-least-once 取り込み + デデュープ（`data_dedupe_drops_total` 監視）。
  - ウォーターマーク: `last_ts` を durable に保存。リカバリ時は `last_ts+1` から再取得。

- 設定（例: `config/pipeline_policy.yaml`）
```yaml
freshness_budget_seconds:
  value:
    "15m": 60
    "1h": 120
    "4h": 180
  label_ja: "反映遅延SLO"

retry_max:
  value: 5
  label_ja: "再試行上限"

circuit_breaker:
  value:
    open_threshold_errors: 5
    half_open_after_seconds: 120
  label_ja: "サーキット設定"

dq_thresholds:
  value:
    missing_rate: 0.05
    outlier_rate: 0.08
    beta_stability_std_jump: 3.0
  label_ja: "DQ閾値"
```

---

### 🧭 データソース抽象化レイヤ v1（Ports & Adapters）

- 目的・方針
  - プロバイダ差（API/命名/分解能/欠損特性）を吸収し、下流は「カノニカル形式」にのみ依存。
  - 新規ソース追加・切替・フェイルオーバを最小変更で実現。契約は YAML/Schema で管理。

- 抽象インターフェース（論理契約）
  - `MarketDataProvider`
    - `fetch_time_series(symbol, timeframe, start_ts, end_ts, limit) -> CanonicalBars`
    - `stream_quotes(symbols[], timeframe|tick) -> CanonicalTicks`（リアルタイム）
    - `list_symbols(filters) -> SymbolMeta[]`
    - `get_capabilities() -> { timeframes, assets, limits, latency_profile }`
    - `get_rate_limit() -> { rest_qps, ws_channels, burst, policy }`
    - `health_check() -> { status, details }`
  - 返却はすべてカノニカルスキーマで統一（下記）。ソース固有フィールドは `metadata` に格納。

- カノニカルスキーマ（抜粋）
  - Bars（OHLCV, UTC, 一意は `symbol,timeframe,ts_utc`）
```yaml
canonical_bar:
  type: object
  required: [ts_utc, symbol, timeframe, open, high, low, close]
  properties:
    ts_utc: { type: string, format: date-time, description: "RFC3339 UTC（ミリ秒以上保持）, 例: 2025-11-03T12:34:56.789Z" }
    symbol: { type: string, description: "カノニカル表記（例:XAUUSD, 大文字・区切りなし）。ソース表記は metadata.symbol_source に格納" }
    timeframe: { type: string, description: "設定の timeframe_allowed で検証（enumは設定側で管理）" }
    open: { type: number }
    high: { type: number }
    low:  { type: number }
    close:{ type: number }
    volume:{ type: [number, "null"], description: "FX/指数では null を許容（0は不明値を意味しない）" }
    quality_flag: { type: string, enum: ["ok","missing","outlier","resampled","conflict","stale","revised"] }
    source_id: { type: string }
    ingest_run_id: { type: string }
    metadata:
      type: object
      additionalProperties: true
      properties:
        symbol_source: { type: string }
        source_latency_ms: { type: number }
        provider_version: { type: string }
        ingest_seq: { type: number }
```
  - Ticks（任意採用）
```yaml
canonical_tick:
  type: object
  required: [ts_utc, symbol]
  properties:
    ts_utc: { type: string, format: date-time }
    symbol: { type: string }
    bid: { type: [number, "null"] }
    ask: { type: [number, "null"] }
    mid: { type: [number, "null"], description: "bid/ask 無い場合は mid を推奨" }
    size: { type: [number, "null"] }
    metadata: { type: object, additionalProperties: true }
```
  - 数値精度の目安: 価格は Decimal 相当で少なくとも小数 6 桁、派生量（ATR 等）は 5 桁を目安。

- ソース登録（sources.yaml 例）
```yaml
providers:
  twelvedata:
    type: TwelveData
    base_url: "https://api.twelvedata.com"
    api_key_ref: "ENV:TWELVEDATA_API_KEY"
    timeframes: ["15m","1h","4h"]
    assets: ["CFD","FX","INDEX"]
    priority: 1
    rate_limits: { rest_qps: 10, ws_channels: 500 }
    cost_tier: "$99"
  secondary_x:
    type: GenericRest
    base_url: "https://..."
    api_key_ref: "VAULT:secret/path"
    timeframes: ["1h"]
    priority: 2
```

- マージ/フェイルオーバ戦略
  - 優先度: `priority` 昇順で primary→secondary。primary 障害時は自動切替、回復後に戻す（サーキット準拠）。
  - 乖離検知: 同一バーの `|close_primary - close_secondary| / price_ref > diff_thresh`（既定 0.003）で `quality_flag=conflict`。
  - デデュープ: キー `(symbol,timeframe,ts_utc)` で一意化。重複は `latest_wins`。
  - リサンプル: 原則禁止。必要時は `resampled` フラグを必須付与。

- DQ・プロベナンス
  - ソース別メトリクス: 欠損率/スパイク率/遅延/再接続回数を計測し、`dq_metrics` に集計。
  - プロベナンス: `source_id, ingest_run_id, checksum` をカノニカルに埋め込み。監査・再現に利用。

- バージョニング/互換性
  - スキーマ: `schema_version = v1`。破壊的変更は `v2` を新設し段階移行。追加は `metadata` で後方互換。
  - アダプタ: `provider_version` を記録し、変更はリリースノート＋PR承認必須。

- セキュリティ
  - `api_key_ref` は ENV/Vault 参照のみ許可。平文キーをYAMLへ直書き禁止。
  - レート/コスト/規約上の制約は `sources.yaml` に明記し、CIで静的検査。

- 適合テスト（Conformance）
  - 取得→カノニカル変換→DQ→保存の最小E2Eをソース毎に自動実行。
  - チェック: 時間整合（UTC/連続性）、型/必須列、欠損/外れ値率、乖離閾値、idempotency。

- 運用
  - 追加/変更は UI→Git→PR→承認→適用→監査（`audit.config_changes`）。
  - フィーチャー切替時はカナリア（対象銘柄20%）→全体展開。

---

### 📈 backtest-assets-engine 仕様 v1（I/O・戦略・ストレス・出力）

- 目的/範囲
  - 学習済みモデル（AI1/AI2）とカノニカルデータを用い、統合ルール（θ1/θ2）で過去検証・ストレス評価を実施。
  - KPI（Sharpe/MaxDD/E per trade/発動率 等）を算出し、採用判定・モデル改善にフィードバック。

- 入力（論理契約）
  - データ: `canonical_bar`（timeframe一致、UTC、連続）
  - モデル: `model_ai1.pkl`, `model_ai2.pkl`, `feature_schema.json`, `params.yaml`（θ1/θ2/M 等）
  - コスト: `cost_table.yaml`（銘柄別 手数料bps/スプレッドbps/想定スリッページbps/スワップ日次）
  - ユニバース: `universe.yaml`（ペア/最小ロット/ティックサイズ/取引時間）
  - 期間: `bt_period {start_ts, end_ts}`（学習期間と非重複のOOSが望ましい）

- 売買ルール（統合意思決定）
  - Entry: `return_prob > θ1 AND risk_score < θ2`
    - 方向: `z>0 → A売/B買`, `z<0 → A買/B売`
    - β中立: 名目額一致（`beta_weight` で調整）。最小ロット/ティックで丸め。
  - Exit: `|z| ≤ z_exit OR elapsed_bars > M OR risk_score ≥ θ_stop`
  - サイズ: `position_scale` を上限 1.0 で適用（AI3が無い場合は 1.0）
  - 追加オプション: ATRベースのタイムストップ/損切り（任意、既定OFF）

- 約定・コストモデル
  - 価格: バー終値近傍で約定。スリッページbpsとスプレッドbpsを両レッグへ適用。
  - 手数料: 片側コミッションbpsを往復で計上。
  - スワップ: 日次でレッグ別に加算（CFD/FX）。週末繰越規則は `cost_table.yaml` に従う。
  - PnL: 基軸通貨換算。ペアPnLは2レッグ合算。実現損益/含み損益を分離集計。

- ストレスシナリオ（最小セット）
  - Volatility Spike: ATR×k（k=1.5/2.0）相当の価格ノイズを注入。
  - Correlation Breakdown: ρを短期に 0〜0.2 へ遷移させる擬似ノイズ。
  - Cost Increase: 手数料+10〜30bp、スリッページ+5〜15bp。
  - Latency/Slippage: 約定を+1バー遅延、またはスリッページ増大。
  - Gap Event: 指定日/時間に±x%のギャップを挿入（x=0.5,1.0,2.0）。

- 出力（論理スキーマ）
  - `bt_summary`（期間別/ペア別）: `pair_id, period, trades, win_rate, e_per_trade, ann_return, sharpe, max_dd, halt_rate, theta1, theta2, params_hash, data_hash`
  - `bt_trades`: `trade_id, timestamp_entry/exit, pair_id, side, qty_A/B, price_A/B, z_at_entry/exit, return_prob, risk_score, cost_commission, cost_slippage, pnl`
  - `bt_daily_equity`: `date, pair_id, equity, dd`
  - `bt_stress_results`: `scenario, pair_id, sharpe, max_dd, ann_return, notes`
  - すべてに `model_version, feature_schema_hash, code_hash, seed, run_id` を付与。

- API/CLI（実装方針）
  - CLI: `bt run --universe u.yaml --period 2022-01:2024-06 --timeframe 1h --model-dir ./models/202510 --cost cost.yaml --out ./bt_out`
  - API: FastAPI で `POST /bt/runs`（非同期実行）, `GET /bt/summary`, `GET /bt/trades` を提供。

- 再現性/シード
  - `seed` 固定、データ・コード・設定のハッシュを `bt_runs` に保存。結果はブロックブートストラップでCI添付。

- 採用判定（再掲・厳格化）
  - 合格: `Sharpe > 1.2 AND MaxDD < 0.12 AND trades_per_year ≥ 150` を満たす。
  - 参考: `やらない勇気発動率 10–40%`, `stop誤検出 < 10%`。

- 設定（backtest_policy.yaml, 例）
```yaml
entry_rule:
  value: { use_theta: true, use_position_scale: true }
exit_rule:
  value: { z_exit: 0.5, M: 48, risk_stop: true, theta_stop: 0.45 }
costs:
  value:
    commission_bps_default: 10
    slippage_bps_default: 8
    spread_bps_table: {}
  label_ja: "コスト既定"
stress:
  value:
    vol_spike: [1.5, 2.0]
    corr_breakdown: [0.0, 0.2]
    cost_increase_bps: [10, 30]
    latency_bars: [1]
    gap_percent: [0.5, 1.0, 2.0]
  label_ja: "ストレス設定"
```

---

### 📊 ml-assets-analytics 仕様 v1（API/KPI/ダッシュボード/レポート）

- 目的
  - 学習・バックテスト・運用のKPIを一元集計・可視化し、リスク通知と採用判断を支援。

- データソース
  - DB: PostgreSQL（`bt_summary`, `bt_trades`, `model_registry`, `signals_live/history`, `analytics.pair_dd_metrics`, `audit.config_changes`, `audit.retrain_runs`）
  - キャッシュ: Redis `analytics_cache`（短期KPI/集計）、`signals`（リアルタイム指標）
  - ストレージ: S3/MinIO（PDF/CSVレポート、静的画像）

- バックエンドAPI（FastAPI 例）
  - `GET /metrics/model?from=..&to=..` → モデル精度・採用履歴
  - `GET /metrics/trading?from=..&to=..&pair_id=` → 収益・DD・勝率・E/trade
  - `GET /metrics/data_quality?from=..&to=..` → 欠損率/outlier率/APIレイテンシ
  - `GET /metrics/risk?from=..&to=..` → `DD_WARN/HALT/FLATTEN` 状況、やらない勇気発動率、θ1/θ2 通過率
  - `POST /alerts/trigger` → 任意アラートの登録（RBAC保護）
  - `POST /reports/generate` → 日次/週次/月次レポート生成（非同期）
  - `GET /reports/download?id=` → レポート取得
  - 応答はページネーション・集計粒度（日/週/月）をサポート

- 主要レスポンス例
```yaml
metrics_trading:
  pair_id: "XAUUSD_XAGUSD"
  timeframe: "1h"
  period: { from: "2025-08-01", to: "2025-10-31" }
  kpis:
    annualized_return: 0.22
    sharpe: 1.45
    max_drawdown: 0.08
    win_rate: 0.62
    e_per_trade: 0.0003
    trades_per_year: 210
    halt_rate: 0.18
  series:
    equity_daily: [{ date: "2025-10-01", equity: 1.035 }, ...]
    dd_daily:     [{ date: "2025-10-01", dd: 0.04 }, ...]
```

- KPI 設計（再掲＋加筆）
  - モデル: `AUC, Brier, PR-AUC, Calibration-ECE`（再学習ごと）
  - 収益/リスク: 年率/Sharpe/MaxDD/Calmar/E per trade/勝率/取引数
  - リスク運用: `やらない勇気発動率(10–40%)`, `DD_WARN/HALT/FLATTEN` 到達、`DD_*_PAIR` 到達率、`leverage_scale` 平均
  - データ品質: 欠損率/outlier率/API遅延、`dq_pass_rate`
  - 運用: uptime/失敗回数/レイテンシ/シグナル数/キュー遅延

- ダッシュボード（Next.js）
  - 構成: モデル／バックテスト／運用／データ品質／リスク／アラートセンター
  - フェッチ戦略: SSR + SWR（5–30s再検証）。機密KPIはサーバサイドのみ集計。
  - 認証/権限: NextAuth+RBAC（`viewer/editor/approver/admin`）。機密エンドポイントはRoleでガード。

- アラート
  - 重大: 連続損失>5、APIダウン>10分、バックテスト不合格 → PagerDuty + Slack `#risk-alerts`
  - 警告: Sharpe低下(-20%)、outlier率>10%、Redis遅延>2s → Slack `#ml-ops`
  - 情報: 再学習成功、月次レポート → Slack `#analytics-info`
  - Slackテンプレートは `slack_policy.yaml` を参照、`label_ja` をUI表示に利用

- レポーティング
  - 日次: KPIサマリ（勝率/年率/MaxDD/やらない勇気率/θ1/θ2通過率/個別DD到達率/レバ縮小率/API統計）
  - 週次: PDF（損益曲線/ヒートマップ/上位下位ペア）、CSV（トレード詳細）
  - 月次: A/B 比較・ストレス結果・改善提案。`backtest.bt_stress_results` を取り込み。
  - 生成結果は S3/MinIO へ保存。保持期間は `data_retention.yaml` の `reports_months` で管理。

- キャッシュ/更新
  - Redisに短期キャッシュ（キー: `analytics:metrics:{scope}:{period}`、TTL 5–15分）。整合性優先箇所は都度DB集計。
  - バッチ: Prefect/Airflowで日次・週次集計を実行。失敗時の再実行はidempotent。

- 設定（analytics_policy.yaml 例）
```yaml
risk_panels:
  value:
    show_pair_dd: true
    show_portfolio_dd: true
    show_leverage_scale: true
  label_ja: "リスクパネル表示"

refresh_intervals_seconds:
  value:
    trading_page: 15
    risk_page: 10
    data_quality_page: 60
  label_ja: "自動更新間隔"

export_limits:
  value: { trades_csv_max_rows: 200000 }
  label_ja: "エクスポート上限"
```

- セキュリティ/監査
  - すべての設定変更・レポート生成要求・アラート抑止は `audit.config_changes` または専用 `audit.analytics_actions` に記録。
  - 個人情報は扱わない前提。外部連携（メール/Slack）資格情報は Secret/Vault 管理。

---

### 🧾 設定変更ワークフロー仕様 v1（UI→Git→PR→承認→適用→監査）

- 対象設定（例）
  - `core_policy.yaml`, `dd_policy.yaml`, `retrain_policy.yaml`, `signals_policy.yaml`, `pipeline_policy.yaml`, `data_retention.yaml`, `analytics_policy.yaml`, `backtest_policy.yaml`, `sources.yaml`, `slack_policy.yaml`

- 役割/RBAC
  - `viewer`（閲覧のみ）、`editor`（編集/PR作成）、`approver`（承認/適用トリガ）、`admin`（全権）
  - 本番適用には `approver` 1名以上の承認必須（高リスク項目は2名）

- ステートマシン
  - `draft → pr_created → approved → merged → applied`
  - 例外: `rejected`（却下）, `rollback_requested → rolled_back`
  - 遷移時に監査ログ更新（`audit.config_changes`）と通知（`#config-changes`）

- イベント（ペイロードは共通エンベロープを使用）
  - `CONFIG_PR_CREATED`: `config_name, branch_name, pr_url, change_summary`
  - `CONFIG_APPROVED`: `approvers[], checklist_url, risk_note`
  - `CONFIG_MERGED`: `merge_sha, merged_at`
  - `CONFIG_APPLY_TRIGGERED`: `target_env, apply_job_id`
  - `CONFIG_APPLIED`: `target_env, applied_at, version, checksum`
  - `CONFIG_ROLLBACK`: `from_version, to_version, reason`

- API（FastAPI 例）
  - `POST /configs/validate`（YAML/差分を受け取り静的検証を実行、詳細は下記）
  - `POST /configs/pr`（ブランチ作成・PR作成、`change_summary` 自動生成）
  - `POST /configs/approve`（RBAC検証・承認記録、チェックリストURL添付）
  - `POST /configs/merge`（CI通過後のみ許可）
  - `POST /configs/apply`（`env=dev|stg|prod`、カナリア/段階適用をサポート）
  - `POST /configs/rollback`（直前安定版へ復帰）
  - `GET /configs/audit?status=&config_name=&from=&to=`（監査照会）

- 静的検証（Validate）
  - YAML構文/スキーマ検証（JSON Schema）
  - 相互整合: `timeframe_default ∈ timeframe_allowed`、`retention ≥ 必要バー数`、`dd_*` 閾値の単調性・範囲
  - 変更リスク評価: レバレッジ/θ/コストの急変は `risk_note` を付与し `approver≥2` を要求
  - ファイルパス制限: 許可された設定ファイル以外の変更は拒否

- CI ゲート
  - スキーマ検証・ユニットテスト・ドライラン（学習/BT/適用のサニティ）
  - 重大アラート時は `CONFIG_REJECTED` 扱い（メッセージと根拠を通知）

- 適用（Apply）
  - 順序: `dev → stg → prod`。カナリア: prod 20%（ペア/戦略単位）→ 100%
  - ランタイム反映: 設定ウォッチャでホットリロード。不可の場合は安全停止→再起動
  - 監査: `config_name, version(yyyyMMdd_HHmm), checksum, merge_sha, applied_by, applied_at, env` を記録

- ロールバック
  - トリガ: KPI悪化（Sharpe -20% or MaxDD +3%）/障害/適用失敗
  - 手順: 直前の安定版 `version` へ即時復帰→監査と通知→事後レビュー

- 通知
  - `#config-changes`: すべての状態遷移（PR/承認/適用/ロールバック）
  - `#risk-alerts`: 高リスク設定の適用/ロールバック時に追加通知

- バージョニング/保持
  - `version = yyyyMMdd_HHmm + short_sha`、最低 5 バージョン保持（`retrain_policy`は10推奨）
  - `data_retention.yaml` に従い履歴/ログ/レポートを保持

---

### 💰 コストテーブル / ユニバース仕様 v1（丸め・発注単位・時間帯）

- 目的
  - ブローカー/銘柄ごとの差異（ティック/ロット/時間帯/スワップ/スプレッド）を設定で一元化し、バックテスト/運用の一貫性を担保。

- ユニバース定義（`config/universe.yaml` 例）
```yaml
pairs:
  - pair_id: "XAUUSD_XAGUSD"
    group: "metals"
    leg_A:
      canonical_symbol: "XAUUSD"
      broker_symbol: "XAUUSD"
      asset_class: "CFD"
      tick_size: 0.01
      price_precision: 2
      contract_size: 1.0
      min_lot: 0.01
      lot_step: 0.01
      base_ccy: "USD"
      timezone: "UTC"
      trading_hours:
        sessions: [{ start: "00:05", end: "23:55" }]
        holidays_calendar: "US"
    leg_B:
      canonical_symbol: "XAGUSD"
      broker_symbol: "XAGUSD"
      asset_class: "CFD"
      tick_size: 0.001
      price_precision: 3
      contract_size: 1.0
      min_lot: 0.01
      lot_step: 0.01
      base_ccy: "USD"
      timezone: "UTC"
      trading_hours:
        sessions: [{ start: "00:05", end: "23:55" }]
        holidays_calendar: "US"
    constraints:
      margin_requirement: 0.05   # = 20x leverage
      min_notional_usd: 100.0
      allowed_timeframes: ["15m","1h","4h"]
```

- コストテーブル（`config/cost_table.yaml` 例）
```yaml
defaults:
  commission_bps: 10          # 片側コミッション（bps）
  slippage_bps: 8             # 片側スリッページ（bps）
  spread_bps: 5               # 名目スプレッド（bps）
  swap:
    rollover_day: "WED"       # FXのトリプルスワップ日
    time_utc: "21:00"

overrides:
  XAUUSD:
    spread_bps: 6
    slippage_bps: 10
    swap: { long_bps_day: -4.0, short_bps_day: 3.0 }
  XAGUSD:
    spread_bps: 8
    slippage_bps: 12
    swap: { long_bps_day: -3.0, short_bps_day: 2.5 }

time_of_day_multipliers:
  # セッション別のスリッページ係数（例）
  "22:00-01:00": 1.5
  "01:00-07:00": 1.2
```

- 取引可能時間・休場
  - エントリー/エグジットは両レッグとも `trading_hours.sessions` 内のみ許可。
  - 休場/祝日（`holidays_calendar`）該当日は新規停止。既存ポジションのクローズは `risk_policy` に従う。

- サイズ決定と丸め（β中立）
  - 目標名目額: `notional_A : notional_B = 1 : |β|`。最小ロット/最小名目を満たすまで比例拡大。
  - 丸め順序: 価格→ティックに丸め → ロットを `min_lot`/`lot_step` で丸め → 名目が `min_notional_usd` 以上を保証。
  - 契約サイズ: `qty_lots × contract_size` を用いて名目額計算。両レッグの丸め後比率が `±1%` 以内になるよう再調整。

- 通貨換算
  - アカウント通貨（既定 `USD`）。異通貨PnLは `fx_rates`（同時間足の最新）で換算。`stale_threshold` 超過なら換算保留。

- コスト適用順序（バックテスト/運用共通）
  1) 価格決定（終値基準） 2) 名目スプレッド適用 3) スリッページ 4) コミッション 5) スワップ（1日1回）

- バリデーション
  - 価格×`tick_size` 整合、ロット丸め、時間帯内執行、最小名目/ロット、`allowed_timeframes` 準拠。

- 設定と運用
  - 変更は設定ワークフローに従い、`universe.yaml`/`cost_table.yaml` を PR→承認→適用。
  - バックテストは `backtest_policy.yaml` で `cost_table.yaml` を参照し、運用は同値を用いる。

---

### 🧯 運用Runbook 仕様 v1（停止/再開/ロールバック）

- 目的
  - 重大イベント時の意思決定と操作手順を標準化し、損失拡大と人的エラーを抑止。

- 役割
  - 実施: `Trading Ops`
  - 承認: `運用責任者`（必須）, `リスク管理者`（再開・ロールバック時は必須）

- 停止レベル（段階）
  - Soft Halt（新規のみ停止）: `DD_WARN` 到達 or 連敗しきい値。
  - Hard Halt（シグナル全停止）: `DD_HALT` 到達 or 重大障害（Redis/DB > 3分）。
  - Flatten（フラット化）: `DD_FLATTEN` 到達 or 個別 `DD_FLATTEN_PAIR` 超過。

- トリガ条件（既存ポリシー連携）
  - ポートフォリオ: `DD_WARN/DD_HALT/DD_FLATTEN`（`dd_policy.yaml`）。
  - 個別ペア: `DD_*_PAIR`（σベース）を超過。
  - システム: `data_pipeline_lag_seconds > freshness_budget`, APIダウン>10分, 推論遅延>200msが継続。

- 操作（API/フラグ）
  - API（FastAPI 例）
    - `POST /ops/halt { scope: portfolio|pair, pair_id?, level: soft|hard }`
    - `POST /ops/flatten { scope: portfolio|pair, pair_id?, mode: immediate|graceful }`
    - `POST /ops/resume { scope: portfolio|pair, pair_id? }`
    - `POST /ops/rollback { target: theta|model|config, version }`
  - ランタイムフラグ（Redis Hash 例）
    - `core:ops:flags → { global_halt, halted_pairs[], flatten_pairs[], leverage_scale }`
    - 参照は推論側が強制。状態は `analytics` が可視化。

- 手順（標準オペ）
  1) 事象検知（自動/手動）→ 影響スコア確認（対象ペア/損失見積/遅延）。
  2) 停止判定:
     - Soft: 新規発注停止（global_halt=soft）。既存は維持、`leverage_scale` を `dd_policy.yaml` に従い縮小。
     - Hard: シグナル生成停止（global_halt=hard）。新規を全面停止。
     - Flatten: `mode=graceful`（流動性に応じ順次クローズ）推奨。急変時は `immediate`。
  3) 通知（Slack `#risk-alerts`）：レベル・対象・理由・リンク（ダッシュボード/Run ID）。
  4) 記録（`incident_logs`）: 時刻・実施者・根拠・スクリーンショット/添付。

- 再開手順（ガード付き）
  - 技術条件: `DD_WARN` 未満へ回復し `stability_days`（既定10営業日）連続、`corr_threshold` 以上（またはコインテグレーション回復）。
  - 手続条件: `resume_checklist_url` の完了、`resume_approved_by` の承認を取得、`resume_approved: true` に更新。
  - 実施: `POST /ops/resume` → `global_halt` 解除 → カナリア再開（20%のペア）→ KPI良好なら全体。

- ロールバック手順
  - 対象: θ（`core_policy.yaml`）, モデル（`model_registry`）, 設定（`audit.config_changes`）。
  - トリガ: KPI悪化（Sharpe -20% or MaxDD +3%）、障害、適用失敗。
  - 実施: `POST /ops/rollback { target, version }` → 監査記録 → PagerDuty/Slack 通知。

- チェックリスト（抜粋）
  - 停止: 影響推定、未約定の有無、重要イベント（指標/ロール）確認、通知準備。
  - 再開: DD/相関/勝率の回復、データ鮮度、コストテーブル更新、モデル/θの比較、承認取得。
  - ロールバック: 影響範囲、依存関係、適用後KPI監視（24–72h）。

- 監査/可観測性
  - すべての `/ops/*` 実行は `audit.analytics_actions` に保存（実行者・理由・期間・差分）。
  - ダッシュボードに `global_halt/flatten_pairs/leverage_scale` を常時表示。

- 設定（runbook_policy.yaml 例）
```yaml
halt_policy:
  value:
    soft_on_dd_warn: true
    hard_on_dd_halt: true
    flatten_on_dd_flatten: true
  label_ja: "停止条件の既定"

resume_policy:
  value:
    stability_days: 10
    corr_threshold: 0.65
    canary_ratio: 0.2
  label_ja: "再開条件・手順"

rollback_policy:
  value:
    sharpe_drop_limit: 0.20
    maxdd_increase_limit: 0.03
  label_ja: "ロールバック基準"
```

---

### ✅ 最終整合チェックリスト v1

- 時間足・窓
  - `timeframe_default ∈ timeframe_allowed`、すべての窓/期間は「バー数」基準で一貫。
  - `history_lookback` が `β/z/ATR` の必要バー数を下回らない。
- ラベリング・特徴量
  - `z_entry/z_exit/M` がポリシーと一致、AI1/AI2 の式・窓が pipeline と一致。
  - クリッピング/ロバスト標準化の閾値が重複箇所で同値。
- θ最適化
  - `θ1, θ2` の探索範囲が `core_policy.yaml` と一致、更新はヒステリシス適用。
- データ
  - `canonical_bar` スキーマ準拠、`quality_flag` と `metadata` を適切に付与。
  - `data_retention.yaml` の保持期間が学習・評価に必要な最小量以上。
- コスト/ユニバース
  - `universe.yaml` の `tick/lot/contract_size` と `cost_table.yaml` の上書きが対象銘柄で整合。
  - 取引時間帯と休日がバックテスト/運用双方で尊重される。
- バックテスト
  - Purged K-Fold と Walk-Forward の期間境界が重複・リークなし。
  - 出力 `bt_*` に `model_version/feature_schema_hash/code_hash/seed` を付与。
- Analytics/Ops
  - Redisキー/チャネルのバージョンとドキュメントが一致。
  - KPI/アラートの閾値が `dd_policy.yaml`/`analytics_policy.yaml` と一致。
- セキュリティ/監査
  - シークレットは ENV/Vault 参照、設定変更は UI→PR→承認→適用→監査ログ反映。
  - WORM 対象（監査/重大ログ）の保持とバックアップ方針が有効。

---

### 🧾 設定YAMLひな形（最小テンプレ）

```yaml
# core_policy.yaml
theta1_initial: { value: 0.70, label_ja: "θ1初期値" }
theta2_initial: { value: 0.30, label_ja: "θ2初期値" }
theta_search_range:
  value: { theta1: [0.60, 0.85], theta2: [0.20, 0.45] }
  label_ja: "θ探索範囲"
```

```yaml
# dd_policy.yaml
rolling_window_business_days: { value: 60 }
dd_warn_portfolio: { value: 0.08 }
dd_halt_portfolio: { value: 0.10 }
dd_flatten_portfolio: { value: 0.12 }
k_warn: { value: 2.5 }
k_halt: { value: 3.5 }
k_flatten: { value: 4.5 }
```

```yaml
# retrain_policy.yaml
retrain_cron: { value: "0 3 1 * *" }
retrain_retry_max: { value: 2 }
retrain_notification_channel: { value: "#ml-ops" }
```

```yaml
# pipeline_policy.yaml
timeframe_default: { value: "1h" }
timeframe_allowed: { value: ["15m","1h","4h"] }
history_lookback_months: { value: 24 }
retry_max: { value: 5 }
```

```yaml
# data_retention.yaml
raw_days: { value: 60 }
canonical_months: { value: 36 }
features_cache_months: { value: 12 }
signals_history_months: { value: 12 }
audit_logs_years: { value: 5 }
```

```yaml
# analytics_policy.yaml
refresh_intervals_seconds:
  value: { trading_page: 15, risk_page: 10, data_quality_page: 60 }
```

```yaml
# backtest_policy.yaml
entry_rule: { value: { use_theta: true, use_position_scale: true } }
exit_rule: { value: { z_exit: 0.5, M: 48, risk_stop: true, theta_stop: 0.45 } }
```

```yaml
# universe.yaml（抜粋）
pairs:
  - pair_id: "XAUUSD_XAGUSD"
    leg_A: { canonical_symbol: "XAUUSD", tick_size: 0.01, min_lot: 0.01, lot_step: 0.01 }
    leg_B: { canonical_symbol: "XAGUSD", tick_size: 0.001, min_lot: 0.01, lot_step: 0.01 }
```

```yaml
# cost_table.yaml（抜粋）
defaults: { commission_bps: 10, slippage_bps: 8, spread_bps: 5 }
overrides: { XAUUSD: { spread_bps: 6 }, XAGUSD: { spread_bps: 8 } }
```

---

### 🛡 非機能要件（NFR）v1

- 性能（SLO）
  - 推論レイテンシ: `< 200ms`（1ペア/新バー）
  - Analytics API: p95 `< 300ms`、ダッシュボード更新間隔 10–60s
  - data freshness: 1h 足で `≤ 120s`
- 可用性（SLA）
  - コア推論/シグナル配信: 月間稼働率 `≥ 99.5%`
  - ダッシュボード閲覧: `≥ 99.0%`
- 容量/スケーラビリティ
  - ペア数: 初期 20–30、将来 50+ を想定（プロセス水平分割）
  - データ: canonical 36ヶ月保持（Parquet/DBパーティション）
- セキュリティ
  - TLS終端、RBAC、2FA（UI）、Secrets は ENV/Vault、監査は WORM にアーカイブ
  - 署名済みモデルのみ適用可、設定変更は承認必須
- 監査/ログ
  - 設定変更・再学習・適用・/ops 実行は全て記録（`audit.*`）
  - ログ保持: 90日（重大は5年）
- バックアップ/DR
  - DB: 日次スナップショット + オフサイト、モデル/レポートはS3/MinIO バージョニング
  - 復旧演習: 四半期ごとにDRテスト

---

### 📝 未決パラメータ TODO 表 v1

| 項目 | 現行値/レンジ | 決定責任 | 見直し頻度 | 状態 |
| --- | --- | --- | --- | --- |
| z_entry/z_exit/M | 2.0 / 0.5 / 48 | ML Eng | 月次 | 仮決定 |
| θ1/θ2 探索範囲 | [0.60–0.85]/[0.20–0.45] | Quant/ML | 月次 | 確定 |
| k_warn/halt/flatten | 2.5 / 3.5 / 4.5 | Risk | 四半期 | 仮決定 |
| trades_min/yr | 150 | Ops/Quant | 半期 | 仮決定 |
| cost_table（銘柄別） | overrides TBD | Ops | 月次 | 未決 |
| time_of_day スリッページ係数 | 1.2/1.5 など | Ops | 月次 | 未決 |
| freshness_budget_seconds | 1h:120s 等 | SRE | 月次 | 仮決定 |
| resume_stability_days | 10 営業日 | Risk/Ops | 月次 | 仮決定 |

---

### 🧩 環境変数・設定キー一覧 v1（ENV / YAML Index）

- 環境変数（ENV）
  - `TWELVEDATA_API_KEY`（data）: TwelveData のAPIキー（必須）
  - `POSTGRES_URL`（shared）: `postgresql://user:pass@host:5432/db`
  - `REDIS_URL`（shared）: `redis://host:6379/0`
  - `STORAGE_BACKEND`（shared）: `NAS|LOCAL|S3|WASABI|B2`
  - `ARCHIVE_PATH`（shared）: `/mnt/archive` または `s3://bucket/path`
  - `SLACK_WEBHOOK_URL`（analytics）: 通知送信用Webhook
  - `PAGERDUTY_INTEGRATION_KEY`（ops）: 重大通知連携
  - `TZ`（all）: `UTC` 推奨
  - `LOG_LEVEL`（all）: `INFO|DEBUG|WARN|ERROR`
  - `SERVICE_ENV`（all）: `dev|stg|prod`

- 設定YAML（主要キーの所在）
  - `core_policy.yaml`: `theta*`, `risk_label_*`
  - `dd_policy.yaml`: `rolling_window_business_days`, `dd_*`, `k_*`, `resume_*`
  - `retrain_policy.yaml`: `retrain_*`, `model_version_retention`
  - `pipeline_policy.yaml`: `timeframe_*`, `retry_max`, `freshness_budget_seconds`, `dq_thresholds`
  - `data_retention.yaml`: `raw_days`, `canonical_months`, `signals_history_months`, `audit_logs_years`
  - `analytics_policy.yaml`: `refresh_intervals_seconds`, `risk_panels`, `export_limits`
  - `backtest_policy.yaml`: `entry_rule`, `exit_rule`, `costs`, `stress`
  - `universe.yaml`: `pairs[].leg_*`, `constraints`, `trading_hours`
  - `cost_table.yaml`: `defaults`, `overrides`, `time_of_day_multipliers`
  - `sources.yaml`: `providers[].type/base_url/api_key_ref/priority/rate_limits`
  - `slack_policy.yaml`: `channels`, `message_templates`

- 検証ルール（静的）
  - ENV: 必須変数未設定時は起動不可（`SERVICE_ENV` に応じ必要なもののみ）
  - YAML: 交差整合（時間足・保持期間・DD閾値の単調性）。スキーマ検証と相互チェックは `configs/validate` で実施。

---

### 🚨 エラーコード / アラートID 命名規約 v1

- 目的
  - 横断的に一貫したエラー/アラート識別子を用い、監視・運用・監査・レポートでの検索性を高める。

- 命名規則
  - 形式: `{DOMAIN}_{CATEGORY}_{CODE}`（英大文字、`_` 区切り）
  - DOMAIN: `DATA|CORE|BT|ANALYTICS|OPS|UI`
  - CATEGORY（例）:
    - `API`, `WS`, `DQ`, `LATENCY`, `STORAGE`, `CONFIG`, `RETRAIN`, `ALERT`, `AUTH`
  - CODE: 英数字3–6桁（例: `TIMEOUT`, `CONNFAIL`, `SCHEMA`, `THRESHOLD`, `REJECTED`）

- 例
  - `DATA_API_TIMEOUT`
  - `DATA_DQ_THRESHOLD`
  - `CORE_INFER_LATENCY`
  - `BT_STRESS_FAIL`
  - `ANALYTICS_ALERT_DISPATCH`
  - `OPS_CONFIG_REJECTED`

- 重大度
  - `severity`: `CRITICAL|WARNING|INFO`
  - CRITICAL は PagerDuty、WARNING/INFO は Slack のみ（ポリシーに準拠）

- ペイロード最低限
  - `error_id`（上記命名）、`event_id`（uuid）、`occurred_at`、`source`、`details{}`、`ui_url`

- 連番ID（任意）
  - システム内での短い連番が必要な場合は `ALRT-000123` 形式を併記（人手運用向け）。

---

### 📜 OpenAPI 概要 v1（主要エンドポイントとスキーマ要約）

- 対象サービス
  - Analytics API, Config API, Ops API, Backtest API

- 共通
  - Base Path: `/api/v1`
  - 認証: Bearer Token（NextAuth/JWT）+ RBAC
  - フォーマット: JSON（RFC3339 時刻）

- エンドポイント一覧（抜粋）
  - Analytics
    - `GET /metrics/model`（qs: from,to）
    - `GET /metrics/trading`（qs: from,to,pair_id）
    - `GET /metrics/data_quality`（qs: from,to）
    - `GET /metrics/risk`（qs: from,to）
  - Config
    - `POST /configs/validate`
    - `POST /configs/pr`
    - `POST /configs/approve`
    - `POST /configs/merge`
    - `POST /configs/apply`
    - `POST /configs/rollback`
    - `GET  /configs/audit`
  - Ops
    - `POST /ops/halt`
    - `POST /ops/flatten`
    - `POST /ops/resume`
    - `POST /ops/rollback`
  - Backtest
    - `POST /bt/runs`
    - `GET  /bt/summary`
    - `GET  /bt/trades`

- 共通レスポンスラッパ
```yaml
ApiResponse:
  type: object
  required: [status, data]
  properties:
    status: { type: string, enum: ["ok","error"] }
    data:   { type: object }
    error:  { type: object, nullable: true, properties: { id: {type: string}, message: {type: string} } }
    request_id: { type: string }
```

- スキーマ断片（例）
```yaml
MetricsTrading:
  type: object
  properties:
    pair_id: { type: string }
    timeframe: { type: string }
    period: { type: object, properties: { from: {type: string, format: date}, to: {type: string, format: date} } }
    kpis: { type: object, properties: { annualized_return: {type: number}, sharpe: {type: number}, max_drawdown: {type: number} } }
    series: { type: object }
```

- OpenAPI 管理
  - `openapi.yaml` をルートに配置、PR時にスキーマ検証とプレビューを CI で実施。
  - 破壊的変更はメジャー `v2` を追加し、`/api/v1` は一定期間維持。

---

### 🗃 データディクショナリ表現規約 v1

- 目的
  - DB/Parquet/JSON の列仕様を統一表現で管理し、変更時の影響範囲を明確化。

- 記述フォーマット（Markdown表 + 概念）
  - 列名（snake_case）、型（DB型/論理型）、精度（小数桁/範囲）、必須/任意、説明、例、備考。

- 例: `bt_trades` データディクショナリ
| 列名 | 型(論理/物理) | 必須 | 説明 | 例 | 備考 |
| --- | --- | --- | --- | --- | --- |
| trade_id | uuid/text | 必須 | 取引ID | 4b1c-... | 一意 |
| pair_id | text | 必須 | ペア識別子 | XAUUSD_XAGUSD |  |
| timestamp_entry | timestamptz | 必須 | エントリー時刻(UTC) | 2025-10-01T12:00:00Z | RFC3339 |
| timestamp_exit | timestamptz | 任意 | エグジット時刻(UTC) | 2025-10-01T18:00:00Z |  |
| side | text | 必須 | 方向 | SHORT_SPREAD | A売/B買 等 |
| qty_a | numeric(18,6) | 必須 | レッグAロット数量 | 0.12 | 丸め規則準拠 |
| qty_b | numeric(18,6) | 必須 | レッグBロット数量 | 0.11 | 丸め規則準拠 |
| price_a | numeric(18,6) | 必須 | 約定価格A | 1852.35 |  |
| price_b | numeric(18,6) | 必須 | 約定価格B | 23.451 |  |
| z_at_entry | numeric(10,5) | 必須 | エントリーz | 2.15300 |  |
| z_at_exit | numeric(10,5) | 任意 | エグジットz | 0.43200 |  |
| return_prob | numeric(6,4) | 任意 | AI1出力 | 0.8200 |  |
| risk_score | numeric(6,4) | 任意 | AI2出力 | 0.1800 |  |
| commission_bps | numeric(8,4) | 任意 | 手数料bps | 10.0000 | 片側 |
| slippage_bps | numeric(8,4) | 任意 | スリッページbps | 8.0000 | 片側 |
| pnl | numeric(18,6) | 任意 | 実現損益(USD) | 12.34 |  |
| model_version | text | 任意 | 使用モデル | 20251014_1235 |  |
| feature_schema_hash | text | 任意 | 特徴量定義ハッシュ | abcd1234 |  |
| code_hash | text | 任意 | コードハッシュ | f00ba7 |  |
| seed | int | 任意 | 乱数seed | 42 |  |

- 記述ルール
  - 数値は意味に応じた精度を明記（価格≥6桁、確率4桁、z/ATR等は5桁目安）。
  - 時刻は `timestamptz` + RFC3339、通貨はUSD表記を既定（異通貨は備考に換算ルール）。
  - 変更時は差分を明示（列追加/型変更/非推奨化）し、影響テーブルを提示。

---

### 🔐 安定運用要件

| 項目     | 内容                          |
| ------ | --------------------------- |
| プロセス監視 | systemd/supervisorで自動再起動    |
| ログ管理   | 各プロセス独立ログ＋日次集約              |
| データ整合性 | SQLite → PostgreSQL 集約バッチ更新 |
| 通信信頼性  | Redis Heartbeat監視（生死監視）     |
| 拡張性    | プロセス追加でペア数を水平拡張可能           |

---

### ✅ 今後の拡張予定（次フェーズ）

* Cron＋SFTPによる自動再学習＆モデル転送
* Redis監視ダッシュボード（Web UI）
* データI/O監査ロガー（信号品質の追跡）
* バックテスト自動評価フレーム統合

---

> この構成により、開発速度・安定性・再現性を最大化しつつ、
> 法人レベルの24h運用に耐えるペアトレードAI基盤を構築できる。
